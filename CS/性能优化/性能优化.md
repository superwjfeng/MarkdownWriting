<img src="linux_perf_tools_full.png">

# CPU性能

## *平均负载*

### 定义

```cmd
$ uptime
 21:55:49 up 9 days, 17:18,  1 user,  load average: 1.17, 0.37, 0.18
```

最后三个数字依次表示过去 1 分钟、5 分钟、15 分钟的平均负载 Load Average

> System load averages is the average number of processes that are either in a runnable or uninterruptible state. A process in a runnable state is either using the CPU or waiting to use the CPU. A process in uninterruptible state is waiting for some I/O access, e.g., waiting for disk. The averages are taken over the three time intervals. Load averages are not normalized for the number of CPUs in a system, so a load average of 1 means a single CPU system is loaded all the time while on a 4 CPU system it means it was idle 75% of the time. -- man page

系统平均负载 是处于可运行 running R 或不可中断状态 uninterruptible D 的进程平均数量。处于可运行状态的进程要么正在使用CPU，要么等待使用CPU。处于不可中断状态的进程正在等待某些I/O访问，例如等待磁盘。这些平均值是在三个时间间隔内进行的。**负载平均值未经过系统中CPU数量的归一化处理（不是除了CPU数量的平均值）**，因此负载平均值为1表示单个CPU系统始终处于负载状态，而对于4个CPU系统，则表示其空闲时间为75％

**不要混淆平均负载和CPU使用率**：如上所述，平均负载包括了 D 状态的进程，这种进程是在等待CPU或IO。也就是说 CPU 密集型、IO密集型 甚至只是排队等待都会提高平均负载值

因此平均负载提供了一个快速查看系统整体性能的手段，反映了整体的负载情况。但是如果只看平均负载本身，我们并不能直接发现，到底是哪里出现了瓶颈，从下面的实验我们可以看出，有可能是CPU密集、IO密集或者进程太多了

### 平均负载为多少时合理

平均负载最理想的情况是等于 CPU 个数，通过下面的命令来得到系统的CPU数

```cmd
$ grep 'model name' /proc/cpuinfo | wc -l
```

注：因为`grep`会输出所有包含 `'model name'` 的行，所以用 `wc`工具来计算文本行数（`-l`选项）

三个平均负载值都有参考意义，因为他们展示了平均负载的时间变动趋势

在实际生产环境中，当平均负载高于CPU数量的70%时，就应该要着手分析排查负载高的问题。当然这个数字并不是绝对的，最好还是把系统的平均负载监控起来，然后根据更多的历史数据，判断负载的变化趋势

## *平均负载实验*

### mpstat

sysstat工具包：包含了常用的 Linux 性能工具，用来监控和分析系统的性能，我们的实验中会用到其中的 mpstat 和 pidstat

mpstat, MultiProcessor Statistics 是一个常用的多核 CPU 性能分析工具，用来实时查看每个 CPU 的性能指标，以及所有 CPU 的平均指标

```cmd
$ mpstat [选项] [时间间隔] [次数]
```

* `-P ALL`：显示所有 CPU 的统计信息
* `-P <CPU>`：显示指定 CPU 的统计信息
* `-u`：显示 CPU 使用率

mpstat 的各个字段的意义

```
11:09:39 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
11:09:44 PM  all   53.04    0.00    0.71    0.10    0.00    0.00    0.00    0.00    0.00   46.15
```

* CPU：用于表示统计数据所针对的 CPU
* `%usr` 表示用户空间程序的 CPU 时间百分比。它包括了用户空间应用程序所消耗的 CPU 时间
* `%nice` 表示低优先级用户进程的 CPU 时间百分比。这些进程的优先级被降低，允许其他更重要的任务优先使用 CPU
* `%sys` 表示内核空间的 CPU 时间百分比。它包括了内核执行系统调用和处理中断的时间
* `%iowait` 表示 CPU 等待 I/O 操作完成的时间百分比。当系统中有进程在等待 I/O 操作（如磁盘读写）完成时，CPU 将花费时间等待这些操作完成
* `%irq` 表示处理硬件中断的 CPU 时间百分比。当硬件设备发送中断请求时，CPU 将花费时间处理这些中断
* `%soft` 表示处理软中断的 CPU 时间百分比。软中断是由内核线程执行的一种形式的中断，用于处理各种内核事件
* `%steal` 表示被虚拟化宿主系统窃取的 CPU 时间百分比。当虚拟机宿主系统需要 CPU 时间时，它可能会从虚拟机中“窃取”一些 CPU 时间来满足需求
* `%guest` 表示运行虚拟机时使用的 CPU 时间百分比
* `%gnice` 表示低优先级的虚拟机进程的 CPU 时间百分比
* `%idle` 表示 CPU 空闲时间的百分比。它表示 CPU 在给定时间段内处于空闲状态的时间比例

### pidstat

pidstat 是一个常用的进程性能分析工具，用来实时查看进程的 CPU、内存、I/O 以及上下文切换等性能指标

```
Average:      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
Average:      115      1152    0.20    0.00    0.00    0.00    0.20     -  mysqld
Average:        0   3583569   99.80    0.00    0.00    0.00   99.80     -  stress
```

* `%usr`：表示用户空间程序的 CPU 时间百分比。这个百分比表示进程在用户态执行代码的时间比例
* `%system`：表示内核空间的 CPU 时间百分比。这个百分比表示进程在内核态执行代码的时间比例
* `%guest`：表示运行虚拟机时使用的 CPU 时间百分比
* `%wait`：表示进程花费在等待 I/O 操作完成上的时间百分比。这个百分比表示进程处于等待状态的时间比例，等待 I/O 操作的完成
* `%CPU`：表示 CPU 利用率，即进程在统计周期内使用的 CPU 时间百分比
* CPU：表示进程所在的 CPU 核心编号
* Command：表示进程的命令或可执行文件的名称

### iostat

iostat, Input/Output Statistics：用于监控磁盘 I/O 活动的工具。iostat 可以提供关于磁盘读写速度、I/O 请求等信息，帮助用户了解系统磁盘的性能状况

### 场景一：CPU 密集型进程

实验之前的状态

```cmd
$ uptime
 22:58:45 up 9 days, 18:20,  3 users,  load average: 0.09, 0.16, 0.12
```

在root下的三个bash中分别输入下面的命令

```cmd
$ stress --cpu 1 --timeout 600 # 在1个cpu核心上开启cpu压测
$ watch -d uptime
 23:08:45 up 9 days, 18:30,  4 users,  load average: 1.14, 0.88, 0.50
$ mpstat -P ALL 5 # 每隔5秒显示一次所有CPU的使用情况
11:09:04 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
11:09:09 PM  all   52.90    0.00    0.71    0.20    0.00    0.00    0.00    0.00    0.00   46.19
11:09:09 PM    0  100.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00
11:09:09 PM    1    4.14    0.00    1.45    0.41    0.00    0.00    0.00    0.00    0.00   94.00
$ pidstat -u 5 1 # 每隔5秒显示一次进程情况，一共显示1次
Average:      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
Average:      115      1152    0.20    0.00    0.00    0.00    0.20     -  mysqld
Average:        0   3583569   99.80    0.00    0.00    0.00   99.80     -  stress
```

我们可以看到是 stress 引起了平均负载的上升

### 场景二：I/O 密集型进程

```cmd
$ stress -i 1 --timeout 600
$ watch -d uptime
 23:30:37 up 9 days, 18:52,  4 users,  load average: 0.98, 0.81, 0.54
$ mpstat -P ALL 5
11:30:09 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
11:30:14 PM  all    3.33    0.00   41.14    0.54    0.00    0.00    0.00    0.00    0.00   54.99
11:30:14 PM    0    3.38    0.00   40.80    0.42    0.00    0.00    0.00    0.00    0.00   55.39
11:30:14 PM    1    3.28    0.00   41.48    0.66    0.00    0.00    0.00    0.00    0.00   54.59
$ pidstat -u 5
Average:      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
Average:        0   3590502    3.37   85.92    0.00    0.82   89.30     -  stress
```

### 场景三：大量进程的场景

当系统中运行进程超出 CPU 运行能力时，就会出现等待 CPU 的进程

```cmd
$ stress -c 8 --timeout 600
$ watch -d uptime
 23:36:33 up 9 days, 18:58,  4 users,  load average: 8.08, 4.45, 2.06
```

## *proc信息*

### /proc/cpuinfo

`/proc/cpuinfo` 文件包含了有关系统中每个CPU的硬件信息。以一台云服务的机器为例，以下是一些常见字段

```
processor	: 1
vendor_id	: GenuineIntel
cpu family	: 6
model		: 85
model name	: Intel(R) Xeon(R) Platinum 8255C CPU @ 2.50GHz
stepping	: 5
microcode	: 0x1
cpu MHz		: 2494.140
cache size	: 36608 KB
physical id	: 0
siblings	: 2
core id		: 1
cpu cores	: 2
apicid		: 1
initial apicid	: 1
fpu		: yes
fpu_exception	: yes
cpuid level	: 13
wp		: yes
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 arat avx512_vnni
bugs		: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa itlb_multihit mmio_stale_data retbleed gds
bogomips	: 4988.28
clflush size	: 64
cache_alignment	: 64
address sizes	: 46 bits physical, 48 bits virtual
power management:
```

* processor：CPU 的编号，表示这是第几个处理器
* vendor_id：制造商标识，这里是 GenuineIntel，表示是英特尔制造的 CPU
* cpu family：CPU 所属的家族，这里是 6。
* model：CPU 模型的标识，这里是 85
* model name：CPU 的具体型号和描述，这里是 Intel(R) Xeon(R) Platinum 8255C CPU @ 2.50GHz
* stepping：步进，表示制造过程中的版本
* microcode：微码版本
* cpu MHz：CPU 的时钟频率，这里是 2494.140 MHz
* cache size：CPU 缓存大小，这里是 36608 KB
* physical id：物理 ID，表示在多个 CPU 的系统中，每个 CPU 有一个唯一的物理 ID
* siblings：处理器的线程数（超线程技术支持的线程数）
* core id：CPU 核心的 ID
* cpu cores：CPU 的核心数
* apicid：Advanced Programmable Interrupt Controller 的 ID
* initial apicid：初始的 APIC ID
* fpu：浮点运算单元（Floating Point Unit）是否存在
* fpu_exception：是否支持浮点运算异常
* cpuid level：CPUID 指令支持的级别
* wp：写保护支持
* **flags：**支持的特性和指令集，例如 fpu、sse、avx 等
* bugs：CPU 的一些已知问题或漏洞，例如 Meltdown、Spectre 等
* bogomips：一个用于衡量 CPU 速度的相对值
* clflush size：Cache Line Flush 大小
* cache_alignment：缓存对齐大小
* address sizes：地址位数，包括物理地址位数和虚拟地址位数
* power management：与电源管理相关的信息

lscpu工具从 sysfs 和 /proc/cpuinfo 收集cpu体系结构信息

### /proc/stat

/proc/stat 提供的就是系统的 CPU 的使用情况 和任务统计信息

```cmd
$ cat /proc/stat
cpu  1428688 6050 984498 165856204 217266 0 14656 0 0 0
cpu0 716210 3316 495193 82937037 109074 0 5427 0 0 0
cpu1 712478 2734 489305 82919166 108191 0 9228 0 0 0
intr 809248901 0 9 0 0 6 0 3 0 0 0 0 0 15 0 840162 0 0 0 0 0 0 0 0 0 0 2307518 2347703 2294477 2375405 0 5484055 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ctxt 1516585875
btime 1705523865
processes 3597164
procs_running 1
procs_blocked 0
softirq 191740700 1 42302625 2 10080583 5632135 0 20257 78852576 107 54852414
```

* cpu的使用情况
  * user（通常缩写为 us），代表用户态 CPU 时间。注意，它不包括下面的 nice 时间，但包括了guest 时间
  * nice（通常缩写为 ni），代表低优先级用户态 CPU 时间，也就是进程的 nice 值被调整为 1-19 之间时的 CPU 时间。这里注意，nice 可取值范围是 -20 到 19，数值越大，优先级反而越低
  * system（通常缩写为 sys），代表内核态 CPU 时间
  * idle（通常缩写为 id），代表空闲时间。注意，它不包括等待 I/O 的时间（iowait）
  * iowait（通常缩写为 wa），代表等待 I/O 的 CPU 时间
  * irq（通常缩写为 hi），代表处理硬中断的 CPU 时间
  * softirq（通常缩写为 si），代表处理软中断的 CPU 时间
  * steal（通常缩写为 st），代表当系统运行在虚拟机中的时候，被其他虚拟机占用的 CPU 时间
  * guest（通常缩写为 guest），代表通过虚拟化运行其他操作系统的时间，也就是运行虚拟机的 CPU 时间
  * guest_nice（通常缩写为 gnice），代表以低优先级运行虚拟机的时间

* intr：自系统启动以来的系统中断数，第一列是总数，后面是不同的中断类型的统计
* ctxt：上下文切换次数
* btime: boot time, in seconds since the Epoch, 1970-01-01 00:00:00 +0000 (UTC)
* processes：系统启动后fork的次数
* procs_running：处于 R 状态的进程
* procs_blocked：处于 D 状态的进程
* softirq：所有CPU的软中断触发情况


## *上下文切换*

# 内存性能

```cmd
$ cat /proc/meminfo
MemTotal:        3481620 kB
MemFree:          552460 kB
MemAvailable:    2420840 kB
Buffers:          209464 kB
Cached:          1648360 kB
SwapCached:            0 kB
Active:           939328 kB
Inactive:        1494852 kB
Active(anon):       1020 kB
Inactive(anon):   586992 kB
Active(file):     938308 kB
Inactive(file):   907860 kB
Unevictable:       29152 kB
Mlocked:           27616 kB
SwapTotal:             0 kB
SwapFree:              0 kB
Dirty:               344 kB
Writeback:             0 kB
AnonPages:        605608 kB
Mapped:           176600 kB
Shmem:              2616 kB
KReclaimable:     309412 kB
Slab:             363520 kB
SReclaimable:     309412 kB
SUnreclaim:        54108 kB
KernelStack:        4320 kB
PageTables:         6396 kB
NFS_Unstable:          0 kB
Bounce:                0 kB
WritebackTmp:          0 kB
CommitLimit:     1740808 kB
Committed_AS:    2429416 kB
VmallocTotal:   34359738367 kB
VmallocUsed:       17256 kB
VmallocChunk:          0 kB
Percpu:             1384 kB
HardwareCorrupted:     0 kB
AnonHugePages:         0 kB
ShmemHugePages:        0 kB
ShmemPmdMapped:        0 kB
FileHugePages:         0 kB
FilePmdMapped:         0 kB
HugePages_Total:       0
HugePages_Free:        0
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB
Hugetlb:               0 kB
DirectMap4k:      362360 kB
DirectMap2M:     3831808 kB
DirectMap1G:     2097152 kB
```

* MemTotal：所有内存 RAM 大小，减去一些预留空间和内核的大小

* MemFree：完全没有用到的物理内存，lowFree+highFree

* MemAvailable: 在不使用交换空间的情况下，启动一个新的应用最大可用内存的大小，计算方式：
  $$
  MemFree+Active(file)+Inactive(file)-\\(watermark+min(watermark,Active(file)+Inactive(file)/2))
  $$

* Buffers: 块设备所占用的缓存页，包括：直接读写块设备以及文件系统元数据，比如superblock使用的缓存页

* Cached：表示普通文件数据所占用的缓存页

* SwapCached: swap cache中包含的是被确定要swapping换页，但是尚未写入物理交换区的匿名内存页。那些匿名内存页，比如用户进程malloc申请的内存页是没有关联任何文件的，如果发生swapping换页，这类内存会被写入到交换区

* Active：包含active anon和active file

* Inactive：包含inactive anon和inactive file

* Active(anon)：anonymous pages（匿名页），用户进程的内存页分为两种：与文件关联的内存页（比如程序文件,数据文件对应的内存页）和与内存无关的内存页（比如进程的堆栈，用malloc申请的内存），前者称为file pages或mapped pages，后者称为匿名页

* Inactive(anon)：见上

* Active(file)：见上

* Inactive(file)：见上

* SwapTotal：可用的swap空间的总的大小（swap分区在物理内存不够的情况下，把硬盘空间的一部分释放出来，以供当前程序使用）

* SwapFree：当前剩余的swap的大小

* Dirty：需要写入磁盘的内存去的大小

* Writeback：正在被写回的内存区的大小

* AnonPages：未映射页的内存的大小

* Mapped：设备和文件等映射的大小

* Slab：内核数据结构slab的大小

* SReclaimable：可回收的slab的大小

* SUnreclaim：不可回收的slab的大小

* PageTables：管理内存页页面的大小

* NFS_Unstable：不稳定页表的大小

* VmallocTotal：Vmalloc内存区的大小

* VmallocUsed：已用Vmalloc内存区的大小

* VmallocChunk：vmalloc区可用的连续最大快的大小

# IO性能

# 网络性能

# 基准测试

## *stress*

stress 是 Linux 的一个压力测试工具，用于模拟系统负载，可以对 CPU、Memory、IO、磁盘进行压力测试

```cmd
$ sudo apt install stress
```

```cmd
$ stress [options]
```

* `-c, --cpu N`：产生 N 个进程，每个进程都循环调用 sqrt 函数产生 CPU 压力
* `-i, --io N`：产生 N 个进程，每个进程循环调用 sync 将内存缓冲区内容写到磁盘上，产生 IO 压力。通过系统调用 sync 刷新内存缓冲区数据到磁盘中，以确保同步。如果缓冲区内数据较少，写到磁盘中的数据也较少，不会产生 IO 压力。在 SSD 磁盘环境中尤为明显，很可能 iowait 总是 0，却因为大量调用系统调用 sync，导致系统 CPU 使用率 sys 升高
* `-m, --vm N`：产生 N 个进程，每个进程循环调用 malloc/free 函数分配和释放内存
* `--vm-bytes B`：指定分配内存的大小
* `--vm-keep`：一直占用内存，区别于不断的释放和重新分配（默认是不断释放并重新分配内存）
* `-d, --hdd N`：产生 N 个不断执行 write 和 unlink 函数的进程（创建文件，写入内容，删除文件）
* `--hdd-bytes B`：指定文件大小
* `-t, --timeout N`：在 N 秒后结束程序
* `-q, --quiet`：程序在运行的过程中不输出信息

## *Google性能评估框架*

google/benchmark

### 安装

````cmd
$ git clone git@github.com:google/benchmark.git
````

### 使用

```c++
#include <vector>
#include <cmath>
#include <benchmark/benchmark.h>

constexpr size_t n = 1<<27;
std::vector<float> a(n);

void BM_for(benchmark::State &bm) {
    for (auto _: bm) {
        // fill a with sin(i)
        for (size_t i = 0; i < a.size(); i++) {
            a[i] = std::sin(i);
        }
    }
}

BENCHMARK(BM_for);

void BM_reduce(benchmark::State &bm) {
    for (auto _: bm) {
        // calculate sum of a 
        for (size_t i = 0; i < a.size(); i++) {
            res += a[i];
        }
        benchmark::DoNotOptimize(res);
    }
}

BENCHMARK(BM_reduce);

BENCHMARK_MAIN();
```

使用起来很方便，只需将需要测试的代码放在 `for (auto _: bm)` 里面即可。它会自动决定要重复多少次， 保证结果是准确的，同时不浪费太多时间

BENCHMARK_MAIN 会自动生成了一个 main 函数， 从而生成一个可执行文件供你运行。运行后会得到测试的结果打印在终端上

google/benchmark 还提供了一些 helper 函数/方法，比如说DoNotOptimize，因为BM_reduce中是一个计算任务，如果不使用res的话编译器会把它优化掉，所以要用DoNotOptimize禁止优化。如果不使用google/benchmark的话就得打印一下res来强制使用它

### 编译

使用编译器编译你的测试代码，确保链接 Google Benchmark 库。需要添加 `-lbenchmark` 和 `-lpthread` 等链接选项

```cmd
$ g++ -o mybenchmark mybenchmark.cpp -lbenchmark -lpthread
```

### 命令行参数

google/benchmark 提供了一些命令行参数，来更好的控制测试的输出行为

## *网站压测*

### Apache ab

ApacheBench / ab是一个用于测试HTTP服务器性能的命令行工具。它是Apache HTTP服务器的一部分，用于评估服务器的性能并测量服务器能够处理的负载

ab 可以模拟多个并发用户向服务器发送请求，以评估服务器在不同负载条件下的性能。ab 可以指定要发送到服务器的请求数量、并发用户数、HTTP请求方法、请求头等参数。ab将收集关于每个请求的信息，包括处理时间、吞吐量等，并在测试完成后生成摘要报告

以下是ApacheBench的一些常用选项：

1. `-n requests`：指定要执行的总请求数
2. `-c concurrency`：指定并发用户数，即同时发送请求的数量
3. `-t timelimit`：指定测试的时间限制，而不是指定请求数量
4. `-k`：启用HTTP KeepAlive功能，在一个HTTP会话中允许多个请求
5. `-H "header"`：添加自定义的请求头
6. `-p POSTfile`：指定包含POST数据的文件
7. `-T content-type`：指定POST请求的Content-Type

### Webbench

https://blog.csdn.net/carefree2005/article/details/120034225

webbench 是 Linux 中的一个网站压测工具，最多可以模拟3万个并发连接去测试网站的负载能力

```cmd
$ sudo apt install universal-ctags # 依赖
$ wget http://home.tiscali.cz/~cz210552/distfiles/webbench-1.5.tar.gz
```

```cmd
$ make
$ make install
```

如果 make 的时候报了一个找不到 `<rpc/types.h>` 的，就去 `webbench.c` 中将 `<rpc/types.h>` 改成 `<sys/types.h>`

```
webbench [option]... URL
  -f|--force               Don't wait for reply from server. 不要等待服务器的回复
  -r|--reload              Send reload request - Pragma: no-cache. 发送重新加载请求
  -t|--time <sec>          Run benchmark for <sec> seconds. Default 30. 运行基准测试时间,默认30秒.
  -p|--proxy <server:port> Use proxy server for request. 使用代理服务器进行请求
  -c|--clients <n>         Run <n> HTTP clients at once. Default one. 并发n个http客户端请求，默认1个
  -9|--http09              Use HTTP/0.9 style requests. 使用HTTP/0.9样式的请求
  -1|--http10              Use HTTP/1.0 protocol. 使用HTTP/1.0协议
  -2|--http11              Use HTTP/1.1 protocol. 使用HTTP/1.1协议
  --get                    Use GET request method. 使用get请求方法
  --head                   Use HEAD request method. 使用head请求方法
  --options                Use OPTIONS request method. 使用选项请求方法
  --trace                  Use TRACE request method. 使用跟踪请求方法
  -?|-h|--help             This information.
  -V|--version             Display program version.
```

```cmd
$ webbench -c 500 -t 60 # 每秒500个并发测试60秒
```



# Perf

perf是Linux操作系统中内置的性能分析工具。它通过使用硬件性能监测器和事件计数器，提供了对程序运行时的诸多性能指标的收集和分析能力。Perf工具可以用于测量和分析各种系统层面的性能指标，包括CPU利用率、指令执行次数、缓存命中率、内存访问模式等

<img src="perf_events_map.png" width="80%">

* 综合性能分析：pert提供了广泛的性能分析功能，包括CPU性能分析、内存分析、事件采样、调用图等。
* 功能强大：通过硬件性能检测器来收集性能数据，可以独立的为每个线程计数，提供更全面的多线程性能分析
* 可扩展性好：perf支持多种分析和报告输出格式，可以根据需要生成文本、图形或其他格式的分析结果。它还可以与其他工具（如gprof2dot）进一步生成多种形式的分析结果

## *硬件 & 事件*

### PMU & MSR

随着现代 CPU 变得越来越复杂，设计开发工程师也需要更多的硬件帮助来收集 CPU 上的数据

Performance Monitor Unit, PMU 是一种硬件组件，通常集成在现代 CPU 中，用于监测和收集有关处理器性能和执行的信息。PMU 提供了对处理器内部活动的详细视图，帮助开发人员和系统管理员优化程序性能、调试问题以及进行系统性能分析

PMU 可以提供各种性能计数器，用于测量处理器执行的指令数量、缓存命中和缓存失效的次数、分支预测的准确性等。通过这些计数器，开发人员可以了解程序的执行情况，找出性能瓶颈并进行优化

软件通过 PMU 中的特殊寄存器 MSR 特殊寄存器来编程。MSR 一般被称为 CPU Counter，MSR分为固定功能 fixed-purpose counter 和 通用功能 general-purpose counter。以Icelake为例，固定功能 counter 有3个，通用通能有3个（关闭hyper-thread后有4个 ）

### Events

```cmd
$ sudo perf list # 部分 events
List of pre-defined events (to be used in -e):

  alignment-faults                                   [Software event]
  bpf-output                                         [Software event]
  alarmtimer:alarmtimer_cancel                       [Tracepoint event]
  alarmtimer:alarmtimer_fired                        [Tracepoint event]
```

Events 指的是用户选择进行性能分析的具体计数器或事件类型，这些events就是预先编程好的，通过counter数据集成的。比如说上面的 BpTkBranch、L1MPKI 等

* Hardware Event 是由 PMU 硬件产生的事件，比如 cache 命中，当需要了解程序对硬件特性的使用情况时，便需要对这些事件进行采样

* Software Event 是内核软件产生的事件，比如进程切换，tick 数等

* Tracepoint event 是散落在内核中的静态 tracepoint 所触发的事件，而 tracepoint 则是散落在内核源码中的一些hook，它们可以在特定的代码被执行到时触发，这些 tracepoint 用来判断程序运行期间内核的行为细节，比如 slab 分配器的分配次数等

  tracepint的对应的sysfs节点在 /sys/kernel/debug/tracing/events 中

## *采集模式*

### Couting mode

### Sampling mode

### Tracing mode

## *安装*

```cmd
sudo apt install linux-tools-common
```

接下来输入 `perf` 会出现下面的内容

```cmd
$ perf
WARNING: perf not found for kernel 5.15.0-88

  You may need to install the following packages for this specific kernel:
    linux-tools-5.15.0-88-generic
    linux-cloud-tools-5.15.0-88-generic

  You may also want to install one of the following packages to keep up to date:
    linux-tools-generic
    linux-cloud-tools-generic
```

以 5.15.0-88 为例，继续安装

```cmd
sudo apt install linux-tools-5.15.0-88-generic
sudo apt install linux-cloud-tools-5.15.0-88-generic
```

### 权限问题

## *Perf的基本使用*

https://perf.wiki.kernel.org/index.php/Main_Page

### Overview

````
❯ perf --help

 usage: perf [--version] [--help] [OPTIONS] COMMAND [ARGS]

 The most commonly used perf commands are:
   annotate        Read perf.data (created by perf record) and display annotated code
   archive         Create archive with object files with build-ids found in perf.data file
   bench           General framework for benchmark suites
   buildid-cache   Manage build-id cache.
   buildid-list    List the buildids in a perf.data file
   c2c             Shared Data C2C/HITM Analyzer.
   config          Get and set variables in a configuration file.
   daemon          Run record sessions on background
   data            Data file related processing
   diff            Read perf.data files and display the differential profile
   evlist          List the event names in a perf.data file
   ftrace          simple wrapper for kernel's ftrace functionality
   inject          Filter to augment the events stream with additional information
   iostat          Show I/O performance metrics
   kallsyms        Searches running kernel for symbols
   kmem            Tool to trace/measure kernel memory properties
   kvm             Tool to trace/measure kvm guest os
   list            List all symbolic event types
   lock            Analyze lock events
   mem             Profile memory accesses
   record          Run a command and record its profile into perf.data
   report          Read perf.data (created by perf record) and display the profile
   sched           Tool to trace/measure scheduler properties (latencies)
   script          Read perf.data (created by perf record) and display trace output
   stat            Run a command and gather performance counter statistics
   test            Runs sanity tests.
   timechart       Tool to visualize total system behavior during a workload
   top             System profiling tool.
   version         display the version of perf binary
   probe           Define new dynamic tracepoints
   trace           strace inspired tool
````

* annotate：解析perf record生成的perf.data文件，显示被注释的代码
* archive：根据数据文件记录的build-id，将所有被采样到的elf文件打包。利用此压缩包，可在任何机器上分析数据文件中记录的采样数据
* bench：perf中内置的benchmark，目前包括两套针对调度器和内存管理子系统的benchmark
* buildid-cache：管理perf的buildid缓存，每个elf文件都有一个独一无二的buildid。buildid被perf用来关联性能数据与elf文件
* buildid-list：列出数据文件中记录的所有buildid
* diff
* evlist
* inject
* record：收集采样信息，并将其记录在数据文件（默认为 perf.data）中。随后可通过其它工具对数据文件进行分析
* report：读取 `perf record` 创建的数据文件，并给出热点分析结果
* stat：执行某个命令，收集特定进程的性能概况，包括CPI、Cache丢失率等
* probe：用于定义动态检查点
* trace：关于syscall的工具

### top

Symbol

* `[.]`：user level 用户态空间，若自己监控的进程为用户态进程，那么这些即主要为用户态的cpu-clock占用的数值
* `[k]`：kernel level 内核态空间
* `[g]`：guest kernel level (virtualization) 客户内核级别
* `[u]`：guest os user space 操作系统用户空间
* `[H]`：hypervisor 管理程序

## *record*

record 需要修改源代码，加入插桩

# 其他

## *gprof*

### intro

gprof是GNU项目中的一个性能分析工具，可用于C和C++程序。它通过在程序中插入计时代码和函数调用跟踪来测量程序执行时间，并生成函数调用图和剖析报告，以帮助确定程序的性能瓶颈

* Pros
  * 和GNU集成，可以跨平台使用
  * 配合第三方工具可以实现比较好的可视化效果
  * 没有perf那么复杂，比较容易使用
* Cons
  * 不能像perf一样通过硬件性能检测器收集数据，其精准度有限，对程序执行时间较短或细粒度性能问题的分析方面可能不够准确
  * 对于多线程和并发程序的性能分析能力有限
  * 主要针对C/C++程序

### 使用

* 使用-pg参数编译程序

  ```cmd
  $ g++ -pg main.cpp-o main.exe
  ```

* 运行程序并正常退出，执行完成后会生成gmon.out文件

  ```cmd
  $ ./main.exe
  ```

* 对使用gprof将生成的gmon.out文件转成可读文件

  ```cmd
  $ gprof main.exe gmon.out > result.txt
  ```

### 函数调用可视化

可以通过gprof2dot工具将 result.txt 转换成调用关系图。Gprof2dot是一个开源的工具，可以将多种性能分析工具分析结果进行可视化。支持pert、valgrid、gprof、vtune等等

* 安装：需要有python环境和graphviz环境

  ```cmd
  $ sudo apt-get install python3 graphviz
  $ pip install gprof2dot
  ```

* 使用

  ```cmd
  $ gprof2dot result.txt | dot -Tpng-o output.png
  ```



# Likwid

https://github.com/RRZE-HPC/likwid/wiki

https://hpc.fau.de/research/tools/likwid/

LIKWID (Like I Knew What I’m Doing) 是一个易用的、清亮的命令行性能分析工具，由 FAU 研发。其主要工具有

* **likwid-topology** : A tool to display the thread and cache topology on multicore/multisocket computers 用于显示多核/多插槽计算机上的线程和缓存拓扑结构
* **likwid-perfctr** : A tool to measure hardware performance counters on recent Intel and AMD processors. It can be used as wrapper application **without modifying the profiled code or with a marker API** to measure only parts of the code. An introduction can be found in here. 用于测量近期的Intel和AMD处理器上的硬件性能计数器
* **likwid-pin** : A tool to pin your threaded application without changing your code. Works for pthreads and OpenMP. 无需修改代码即可将多线程应用程序进行固定到特定的核心上
* **likwid-bench** : Benchmarking framework allowing rapid prototyping of threaded assembly kernels. 用于快速原型设计线程汇编内核的基准测试框架
* **likwid-mpirun** : Script enabling simple and flexible pinning of MPI and MPI/threaded hybrid applications. With integrated likwid-perfctr support. 脚本，支持MPI和MPI/线程混合应用程序的简单灵活固定
* **likwid-powermeter** : Tool for accessing RAPL counters and query Turbo mode steps on Intel processor. RAPL counters are also available in likwid-perfctr. 用于访问Intel处理器上的RAPL计数器和查询Turbo模式步骤
* **likwid-memsweeper** : Tool to cleanup ccNUMA domains and last level caches. 用于清理ccNUMA域和最后一级缓存
* **likwid-setFrequencies** : Tool to set the clock frequency of hardware threads. 用于设置硬件线程的时钟频率
* **likwid-agent** : Monitoring agent for LIKWID with multiple output backends. 监控代理，支持多个输出后端
* **likwid-genTopoCfg** : Config file writer that saves system topology to file for faster startup. 配置文件编写器，将系统拓扑结构保存到文件以加速启动
* **likwid-perfscope** : Tool to perform live plotting of performance data using gnuplot. 用于使用gnuplot执行性能数据的实时绘图

## *likwid-perfctr*

```
-h, --help            帮助信息
-v, --version         版本信息
-V, --verbose <level> 日志打印等级, 0 (only errors), 1 (info), 2 (details), 3 (developer)
-c <list>             要测量的处理器ID (必选), 例如 1,2-4,8
-C <list>             固定线程并测量的处理器ID, e.g. 1,2-4,8
                      有关更多 <list> 的语法, 参见 likwid-pin
-G <list>             要测量的GPU ID
-g, --group <string>  CPU的性能组或自定义事件集字符串
-W <string>           英伟达GPU的性能组或自定义事件集字符串
-H                    获得性能组的帮助 (与 -g 选项一起用)
-s, --skip <hex>      用于跳过线程的比特位掩码
-M <0|1>              设置如何访问MSR寄存器, 0=直接, 1=访问守护进程
-a                    列出可用的性能组
-e                    列出可用事件和计数器寄存器
-E <string>           列出可用事件和对应的计数器中匹配<string>的计数器(不区分大小写)
-i, --info            打印CPU信息
-T <time>             以给定的频率切换事件集
模式:
-S <time>             听诊器模式的周期，以s, ms 或 us 为单位, 比如 20ms
-t <time>             时间线模式的频率，以 s, ms 或 us 为单位, 比如 300ms
-m, --marker          在代码中使用Marker API
输出选项:
-o, --output <file>   保存输出到文件. (可选: 根据文件名后缀应用文本过滤器)
-O                    输出可解析的 CSV 而不是 fancy tables
```



# BPF

# 火焰图

## *SystemTap*

https://blog.csdn.net/han2529386161/article/details/103428728





火焰图是由 Linux 性能优化大师 Brendan Gregg 发明的，从宏观角度查看时间花在了哪里

* X轴
  * 由多个方块组成，每个方块表示一个函数
  * 函数在X轴占据的宽度越宽，表示它被采样到的次数越多，可以简单的粗暴的近似理解为执行时间
* Y轴
  * 表示函数调用栈，调用栈越深，火焰就越高
  * 顶部是 CPU 正在执行的函数，下方都是它的父函数

### 生成火焰图

1. 采集堆栈：perf、SystemTap、sample-bt
2. 折叠堆栈：stackcollapse.pl
3. 生成火焰图：flamegraph.pl

# Intel Vtune profiler

Intel VTune profiler是一款功能强大的性能分析工具，针对Intel处理器和架构进行了优化。它可以提供广泛的性能分析功能，包括CPU
使用率、内存访问模式、并行性分析等。VTune profiler支持Windows和Linux操作系统

* 性能强大，和pert一样可以通过硬件事件采样，而且可以对多个维度分析线程、内存、cache、ofiload
* 用户友好：提供使用简便的GUI，使用起来非常方便，也支持命令行
* 丰富的可视化和报告功能：VTune提供直观的可视化界面和丰富的报告功能，使得性能数据和分析结果易于理解和解释。开发人员可以通过图表、图形化界面和报告来展示和分享性能分析的结果。
* 跨平台，支持Windows和linux系统
* 支持本地和远程调试